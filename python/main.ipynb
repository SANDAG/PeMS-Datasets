{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f57a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: d11_text_station_5min_2023_08_20.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_21.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_22.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_23.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_24.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_25.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_26.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_27.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_28.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_29.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_30.txt.gz\n",
      "Loading: d11_text_station_5min_2023_08_31.txt.gz\n",
      "Loading: d11_text_station_day_2023_08.txt.gz\n",
      "Loading: d11_text_station_hour_2023_08.txt.gz\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import gzip\n",
    "import pyodbc\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from zipfile import ZipFile\n",
    "from datetime import datetime\n",
    "\n",
    "# TODO: set SQL connection to location that contains the PeMS objects\n",
    "server = \"\"\n",
    "database = \"\"\n",
    "\n",
    "# TODO: set file location where pems data is saved\n",
    "pems_data_folder = \"../data/\"\n",
    "\n",
    "# set sqlalchemy engine\n",
    "engine = sqlalchemy.create_engine(\n",
    "    f\"mssql+pyodbc://@{server}/{database}?driver=SQL+Server\"\n",
    ")\n",
    "\n",
    "# set pyodbc connection\n",
    "conn = pyodbc.connect(\n",
    "    \"DRIVER={SQL Server};\"\n",
    "    f\"SERVER={server};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# create mappings of PeMS data-set raw file names to PeMS objects\n",
    "mapping = [\n",
    "    {\"file\": \"all_text_tmg_vclass_hour\", \"tbl\": \"pems.census_vclass_hour\"},\n",
    "    {\"file\": \"d11_text_station_5min\", \"tbl\": \"pems.station_five_minute\"},\n",
    "    {\"file\": \"d11_text_station_aadt\", \"tbl\": \"pems.station_aadt\"},\n",
    "    {\"file\": \"d11_text_station_day\", \"tbl\": \"pems.station_day\"},\n",
    "    {\"file\": \"d11_text_station_hour\", \"tbl\": \"pems.station_hour\"},\n",
    "    {\"file\": \"d11_text_meta\", \"tbl\": \"pems.station_metadata\"},\n",
    "    {\"file\": \"pems_holiday_insert\", \"tbl\": \"pems.holiday\"},\n",
    "]\n",
    "\n",
    "# for each PeMS data-set load all files in the data folder\n",
    "# into their respective PeMS SQL object\n",
    "for root, dirs, files in os.walk(pems_data_folder):\n",
    "    # for each file in the data folder\n",
    "    for file in files:\n",
    "        print(\"Loading: \" + file)\n",
    "        path = os.path.join(root, file)\n",
    "\n",
    "        # only expect ZIP or GZ or TXT files in the data folder\n",
    "        if not (file.endswith(\".gz\") or file.endswith(\".zip\") or file.endswith(\".txt\")):\n",
    "            msg = \"unexpected file extension (.gz or .zip ot .txt files expected)\"\n",
    "            raise ValueError(msg)\n",
    "        else:\n",
    "            if file.endswith(\".txt\"):\n",
    "                writePath = path\n",
    "\n",
    "            else:\n",
    "                # if the compressed archive is a ZIP file extract the compressed\n",
    "                # GZ file from the ZIP archive, this is required only for the\n",
    "                # PeMS Data Clearinghouse Station AADT source of which we only\n",
    "                # extract the Station AADT Month Hour data-set\n",
    "                if file.endswith(\".zip\"):\n",
    "                    with ZipFile(path) as zipfile:  # extract file of interest\n",
    "                        for info in zipfile.infolist():\n",
    "                            if \"d11_text_station_aadt_month_hours_\" in info.filename:\n",
    "                                zipfile.extract(info.filename, path=root)\n",
    "                                file = info.filename\n",
    "                    os.remove(path)\n",
    "                    path = os.path.join(root, file)\n",
    "\n",
    "                # write out the underlying data file from the compressed GZ file\n",
    "                writePath = path.rstrip(\".gz\")\n",
    "                with open(writePath, \"wb\") as writeFile:\n",
    "                    # the Census V-Class Hour data-sets have 112 empty fields appended\n",
    "                    # past the fields provided in the metadata\n",
    "                    if \"all_text_tmg_vclass_hour\" in file:\n",
    "                        for line in gzip.open(path):\n",
    "                            line = line.replace(b\",\" * 112, b\"\")\n",
    "                            writeFile.write(line)\n",
    "                    else:\n",
    "                        writeFile.write(gzip.open(path).read())\n",
    "                writeFile.close()\n",
    "\n",
    "        # bulk load underlying data file to SQL Server\n",
    "        # destination is dependent on the PeMS Data Clearinghouse source\n",
    "        sqlTbl = None\n",
    "        for item in mapping:\n",
    "            if item[\"file\"] in file:\n",
    "                sqlTbl = item[\"tbl\"]\n",
    "\n",
    "        if sqlTbl is None:\n",
    "            msg = \"no SQL destination mapped\"\n",
    "            raise ValueError(msg)\n",
    "        else:\n",
    "            if sqlTbl == \"pems.station_metadata\":\n",
    "                # convert to GeoDataFrame and load to SQL Database\n",
    "                df = pd.read_csv(path, delimiter=\"\\t\")\n",
    "                df.columns = [\n",
    "                    \"station\",\n",
    "                    \"freeway\",\n",
    "                    \"direction\",\n",
    "                    \"district\",\n",
    "                    \"county\",\n",
    "                    \"city\",\n",
    "                    \"state_postmile\",\n",
    "                    \"absolute_postmile\",\n",
    "                    \"latitude\",\n",
    "                    \"longitude\",\n",
    "                    \"length\",\n",
    "                    \"type\",\n",
    "                    \"lanes\",\n",
    "                    \"name\",\n",
    "                    \"user_id_1\",\n",
    "                    \"user_id_2\",\n",
    "                    \"user_id_3\",\n",
    "                    \"user_id_4\",\n",
    "                ]\n",
    "                match = re.search(r\"((\\d+)_(\\d+)_(\\d+))\", writePath)\n",
    "                df.insert(\n",
    "                    loc=0,\n",
    "                    column=\"metadata_date\",\n",
    "                    value=datetime.strptime(match.group(1), \"%Y_%m_%d\").strftime(\n",
    "                        \"%Y-%m-%d\"\n",
    "                    ),\n",
    "                )\n",
    "                df.to_sql(\n",
    "                    name=\"station_metadata\",\n",
    "                    schema=\"pems\",\n",
    "                    con=engine,\n",
    "                    if_exists=\"append\",\n",
    "                    index=False,\n",
    "                )\n",
    "\n",
    "                # alter df in SQL\n",
    "                sql = \"\"\"\n",
    "                    UPDATE [pems].[station_metadata]\n",
    "                    SET [shape] = geometry::Point([longitude], [latitude], 4326)\n",
    "                    WHERE [longitude] IS NOT NULL AND [latitude] IS NOT NULL\n",
    "                \"\"\"\n",
    "                engine.execute(sql)\n",
    "            else:\n",
    "                sql = (\n",
    "                    \"BULK INSERT \"\n",
    "                    + sqlTbl\n",
    "                    + \" FROM '\"\n",
    "                    + os.path.realpath(writePath)\n",
    "                    + \"' \"\n",
    "                    + \"WITH (TABLOCK, CODEPAGE = 'ACP', FIELDTERMINATOR=',', ROWTERMINATOR='0x0a');\"\n",
    "                )\n",
    "                cursor.execute(sql)\n",
    "                cursor.commit()\n",
    "\n",
    "        # delete underlying data file\n",
    "        os.remove(writePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pemsDatasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd7edc23bc84f7ae80643de8b88d0caf17b49425fd829870a291738567c82d78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
